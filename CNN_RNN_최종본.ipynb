{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMUJOgPIXxo3",
        "outputId": "18d0636d-9ce4-46bf-9af7-e89248009fc6"
      },
      "outputs": [],
      "source": [
        "#데이터셋 다운로드 및 압축 해제\n",
        "  #현재 google com 내 워킹 디렉토리 위치 파악(이건 무조건 해야 됨!)\n",
        "import os\n",
        "\n",
        "current_directory = os.getcwd()\n",
        "print(\"Current Working Directory:\", current_directory)\n",
        "\n",
        "import requests\n",
        "import tarfile\n",
        "\n",
        "# 데이터셋 다운로드 URL\n",
        "data_url = \"http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\"\n",
        "\n",
        "# 다운로드할 경로 설정\n",
        "download_dir = \"/content\"\n",
        "\n",
        "# 다운로드 받을 디렉토리 생성\n",
        "if not os.path.exists(download_dir):\n",
        "    os.makedirs(download_dir)#download_dir 경로에 디렉터리 만들기\n",
        "\n",
        "# 데이터셋 다운로드\n",
        "download_path = os.path.join(download_dir, \"VOCtrainval_06-Nov-2007.tar\")\n",
        "response = requests.get(data_url, stream=True)\n",
        "with open(download_path, \"wb\") as file:\n",
        "    for chunk in response.iter_content(chunk_size=8192):\n",
        "        if chunk:\n",
        "            file.write(chunk)\n",
        "\n",
        "# 압축 해제\n",
        "with tarfile.open(download_path, \"r\") as tar:\n",
        "    tar.extractall(download_dir)\n",
        "\n",
        "# 압축 파일 삭제\n",
        "os.remove(download_path)\n",
        "\n",
        "print(\"PASCAL VOC 2007 데이터셋 다운로드 및 압축 해제 완료.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KauuaNSKP8GM",
        "outputId": "6d073f80-bf29-427b-9919-a1b370d438a9"
      },
      "outputs": [],
      "source": [
        "#데이터 셋으로부터 이미지, 라벨들만 뽑아내고, 이미지 파일을 numpy 배열(n_H*n_W*n_ch) 형태로 바꾸기\n",
        "\n",
        "#전처리 시작\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "\n",
        "class image_label_extract():\n",
        "  def __init__(self,sample_num):# sample_num은 내가 데이터셋에서 쓸 sample 수 - 전체 sample을 이용할 거면, 0\n",
        "  # 데이터셋 디렉토리 설정\n",
        "    dataset_dir = \"/content/VOCdevkit/VOC2007\"\n",
        "    jpeg_images_dir = os.path.join(dataset_dir, \"JPEGImages\")#JPEGimage들이 있는 디렉터리 주소\n",
        "    annotations_dir = os.path.join(dataset_dir, \"Annotations\")#각 image에 대응되는 주석들이 저장됨.\n",
        "\n",
        "  # JPEGImages 디렉토리 내의 이미지 파일 목록 가져오기\n",
        "    image_files = [f for f in os.listdir(jpeg_images_dir) if f.endswith('.jpg')]\n",
        "\n",
        "  #모든 image 샘플들을 하나의 집합으로(이후 4차원 Tensor로 만들 것) - 이 images list에는 numpy 배열 type의 image를 저장하게 할 것\n",
        "    self.images=list([])\n",
        "    self.rare_images=list([])\n",
        "  #각 image에 대응되는 label들의 쌍을 하나의 집합(multi_labels)으로\n",
        "    self.multi_labels=list([])\n",
        "    if sample_num==0:#0이면 전체 샘플을 사용할 것이라는 의미\n",
        "      for image_file in image_files:\n",
        "        image_path = os.path.join(jpeg_images_dir, image_file)#각 image들의 주소(위치)\n",
        "        labels=list([])#각 image에 들어있는 모든 object name들이 들어갈 것\n",
        "\n",
        "      # 이미지 출력\n",
        "        image = Image.open(image_path)#해당 주소의 image 객체 생성\n",
        "\n",
        "      # 해당 이미지에 대응하는 주석 파일 불러오기\n",
        "        annotation_file = os.path.splitext(image_file)[0] + '.xml'\n",
        "        annotation_path = os.path.join(annotations_dir, annotation_file)\n",
        "\n",
        "      # 주석 파일 파싱\n",
        "        tree = ET.parse(annotation_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "      # 객체 정보 출력(이미지 내 존재하는 객체들의 이름 출력)\n",
        "        for obj in root.findall('object'):#각 image에 대응되는 주석 파일에 있는 object들을 하나씩 불러오는 것.(즉, image에 있는 object를 ....)\n",
        "          name = obj.find('name').text\n",
        "          labels.append(name)\n",
        "        image_array = np.array(image)\n",
        "        self.images.append(image_array)\n",
        "        self.rare_images.append(image)#전처리 안 한 img도 따로 저장할 것\n",
        "        self.multi_labels.append(labels)#각각의 labels들이 묶음이 되도록 만들기\n",
        "    else:\n",
        "      for image_file in image_files[:sample_num]:\n",
        "        image_path = os.path.join(jpeg_images_dir, image_file)#각 image들의 주소(위치)\n",
        "        labels=list([])#각 image에 들어있는 모든 object name들이 들어갈 것\n",
        "\n",
        "      # 이미지 출력\n",
        "        image = Image.open(image_path)#해당 주소의 image 객체 생성\n",
        "\n",
        "      # 해당 이미지에 대응하는 주석 파일 불러오기\n",
        "        annotation_file = os.path.splitext(image_file)[0] + '.xml'\n",
        "        annotation_path = os.path.join(annotations_dir, annotation_file)\n",
        "\n",
        "      # 주석 파일 파싱\n",
        "        tree = ET.parse(annotation_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "      # 객체 정보 출력(이미지 내 존재하는 객체들의 이름 출력)\n",
        "        for obj in root.findall('object'):\n",
        "          name = obj.find('name').text\n",
        "          labels.append(name)\n",
        "        image_array = np.array(image)#image를 numpy로 맞춰야됨!\n",
        "        \n",
        "        self.images.append(image_array)\n",
        "        self.rare_images.append(image)\n",
        "        self.multi_labels.append(labels)#각각의 labels들이 묶음이 되도록 만들기\n",
        "\n",
        "\n",
        "    print(\"multi_labels 개수 : \", len(self.multi_labels))\n",
        "\n",
        "    #단어들을 전체 문장들에서 나타난 빈도수에 맞춰 각 리스트 원소 정렬시키기!\n",
        "    print(\"정렬 전 multi_labels : \",self.multi_labels)\n",
        "    word_counts = Counter(word for sentence in self.multi_labels for word in sentence)\n",
        "    #print(type(word_counts))\n",
        "    for sentence in self.multi_labels:\n",
        "      sentence.append(\"end\")\n",
        "\n",
        "    #print(\"중복 단어 제거 전, sentence들 : \", self.multi_labels)\n",
        "    for i in range(len(self.multi_labels)):\n",
        "      unique_words = []\n",
        "      for word in self.multi_labels[i]:\n",
        "        if word not in unique_words:\n",
        "          unique_words.append(word)\n",
        "      self.multi_labels[i]=unique_words\n",
        "\n",
        "    #print(\"images 개수 : \", len(self.images))\n",
        "\n",
        "#main에 쓸 부분\n",
        "image_label=image_label_extract(0)#전체 샘플 뽑고 싶으면, 0 입력\n",
        "image_list = image_label.images\n",
        "multi_labels = image_label.multi_labels\n",
        "#print(\"multi_labels 개수 : \", len(multi_labels))\n",
        "#print(image_label.multi_labels)\n",
        "#print(\"images 개수 : \", len(image_list))\n",
        "#print(\"images type : \", type(image_list))#list임\n",
        "#print(\"multi_labels = \",multi_labels)\n",
        "#print(\"multi_labels type : \", type(multi_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFbrP4j3ac0e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import skipgrams#skipgrams 함수는 Skip-gram 모델을 학습하기 위해 필요한 학습 데이터를 생성하는 역할 -> 즉, SGNS 데이터셋을 만드는 과정 참고해보면,\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Dot, Dense, LSTM, Layer, Activation\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences#문장 패딩해주는 애\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class word_processing_layer():\n",
        "  def __init__(self,sentences,images,embedding_dimension):\n",
        "    self.multi_labels = sentences\n",
        "    self.images=images\n",
        "      #2-1-1 : sentences의 원소들 중, None or []이 있는 index 뽑기 그 후, 해당 index 제거! 이에 대응되는 image도 전부 지워줘야 됨!\n",
        "    indices_of_none_or_x = [index for index, item in enumerate(self.multi_labels) if item is None or item==[]]\n",
        "    self.multi_labels = [self.multi_labels[index] for index in range(len(self.multi_labels)) if index not in indices_of_none_or_x]\n",
        "    self.images = [self.images[index] for index in range(len(self.images)) if index not in indices_of_none_or_x]환\n",
        "\n",
        "      #2-1-2 : multi_labels에서 object 1개짜리만 있는 img들의 index 확인 및 multi_labels, images의 image 제거(중심-주변 단어 embedding(SGNS) 할 때, 이들은 의미가 없기에)\n",
        "    indices_of_1 = [index for index, item in enumerate(self.multi_labels) if len(item)==1]\n",
        "    self.multi_labels = [self.multi_labels[index] for index in range(len(self.multi_labels)) if index not in indices_of_1]\n",
        "    self.images = [self.images[index] for index in range(len(self.images)) if index not in indices_of_1]\n",
        "    self.images = np.array(self.images)\n",
        "\n",
        "      #2-2 : 정수 인코딩\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(self.multi_labels)\n",
        "    self.vocab = tokenizer.word_index#단어 집합(어휘사전)\n",
        "\n",
        "\n",
        "      #문장(multi_labels)들을 정수 인코딩된 형태로 나타내어 저장하기 / tokenizer로 문장 정수 인코딩할 땐, self.multi_labels처럼, 리스트[] 안에, 각 문장들이 토큰화되어 []로 저장되어 있어야 한다!\n",
        "    self.encoded_multi_labels=tokenizer.texts_to_sequences(self.multi_labels)#토큰화된 sample 문장들의 각 토큰을 정수로 -> 나중에 패딩 후, 각 정수는 embedding vector들로 표현되어 input 데이터가 될 것!\n",
        "    #tokennizer로부터 encoding된 multi_label 구하면, 이는 list!\n",
        "    #print('문장의 최대 길이 :',max(len(sentence) for sentence in self.encoded_multi_labels))\n",
        "    #print('리뷰의 평균 길이 :',sum(map(len, self.encoded_multi_labels))/len(self.encoded_multi_labels))\n",
        "    plt.hist([len(sentence) for sentence in self.encoded_multi_labels], bins=50)\n",
        "    plt.xlabel('length of samples')\n",
        "    plt.ylabel('number of samples')\n",
        "    plt.show()#보면, 문장 최대 4 이상은 거의 없기에, 이후 패딩시, 패딩 길이 4으로 하기!\n",
        "\n",
        "\n",
        "\n",
        "    self.vocab_size = len(self.vocab) + 1  \n",
        "    #print('단어 집합의 크기 :', self.vocab_size)\n",
        "    self.idx2vocab = {value : key for key, value in self.vocab.items()}\n",
        "    self.idx2vocab[0] = \"<pad>\"\n",
        "    #print(\"idx2vocab = \",self.idx2vocab)\n",
        "\n",
        "\n",
        "    #2-3 SGNS\n",
        "       #2-3-1 : SGNS 모델 구성\n",
        "    input_center = Input(shape=(1,), dtype=tf.int32)\n",
        "    input_context = Input(shape=(1,), dtype=tf.int32)\n",
        "    embedding_layer = Embedding(input_dim=self.vocab_size, output_dim=embedding_dimension)\n",
        "    center_embedding = embedding_layer(input_center)\n",
        "    context_embedding = embedding_layer(input_context)#주변 단어 ...\n",
        "    dot_product = Dot(axes=2)([center_embedding, context_embedding])#두 emb vector의 내적\n",
        "    output = Dense(1, activation='sigmoid')(dot_product)#이 것에 sigmoid만 씌운 것\n",
        "    model = tf.keras.Model(inputs=[input_center, input_context], outputs=output)\n",
        "\n",
        "        # 손실 함수 정의 및 모델 컴파일\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        #SGNS 모델 학습\n",
        "    for epoch in range(1, 6):\n",
        "        #2-3-1 네거티브 샘플링\n",
        "        self.skip_grams = [skipgrams(sample, vocabulary_size=self.vocab_size, window_size=2) for sample in self.encoded_multi_labels]\n",
        "        loss = 0\n",
        "        for _, elem in enumerate(self.skip_grams):\n",
        "            first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n",
        "            second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n",
        "            labels = np.array(elem[1], dtype='int32')\n",
        "            X = [first_elem.reshape(-1,1), second_elem.reshape(-1,1)]\n",
        "            Y = labels.reshape(-1,1)\n",
        "            loss += model.train_on_batch(X,Y)[0]\n",
        "            accuracy=  model.train_on_batch(X,Y)[1]\n",
        "        #print('Epoch :',epoch, 'Loss :',loss, 'accuracy : ',accuracy)\n",
        "\n",
        "    # 단어 임베딩 추출\n",
        "    self.word_embeddings_table = embedding_layer.get_weights()[0]\n",
        "    #print(\"embedding tabel shape : \",self.word_embeddings_table.shape)\n",
        "    #print(\"type(self.word_embeddings_table) : \",type(self.word_embeddings_table))\n",
        "\n",
        "    # 2-4 패딩\n",
        "    #print(\"self.multi_labels(토큰화된 정수 인코딩 전 문장들의 list) = \",self.multi_labels)\n",
        "    #print(\"self.encoded_multi_labels type = \",type(self.encoded_multi_labels)) \n",
        "    #print(\"self.encoded_multi_labels(토큰화된 정수 인코딩 후 문장들의 list) = \",self.encoded_multi_labels)\n",
        "\n",
        "    self.encoded_multi_labels_padded_for_answer = pad_sequences(self.encoded_multi_labels, maxlen=4,padding='post')\n",
        "    #print(\"self.encoded_multi_labels_padded_for_answer : \\n\",self.encoded_multi_labels_padded_for_answer)#이건 정답 label이기에, embedding은 필요 x -> 그냥 정답 label로서 train할 때만 필요!\n",
        "    #print(\"self.encoded_multi_labels_padded_for_answer shape =\",self.encoded_multi_labels_padded_for_answer.shape)\n",
        "\n",
        "    #패딩했을 때, 0으로 끝나지 않는 sample들의 index를 모두 찾아 이에 대응되는 images와 함께 제거\n",
        "    non_zero_rows = np.where(self.encoded_multi_labels_padded_for_answer[:, -1] != 0)[0]#non_zero_rows는 이 padding된 sentence들에서 마지막 열이 0이 아닌 행들의 index를 모은 np.array.\n",
        "    #print(\"마지막 열이 0이 아닌 sentence(행)의 index 모음(array) : \\n\",non_zero_rows)\n",
        "    #print(type(non_zero_rows))#numpy 배열\n",
        "\n",
        "    self.encoded_multi_labels_padded_for_answer = np.delete(self.encoded_multi_labels_padded_for_answer, non_zero_rows, axis=0)#마지막 열이 0이 아닌 행(axis=0)들을 모두 제거함.\n",
        "    #print(\"제거 후 남은 sentence 수와 image 수가 동일해야 서로 대응되는 index들이 제거되었음을 알 수 있다.\")\n",
        "    #print(\"제거 후 남은 sentence 수\",len(self.encoded_multi_labels_padded_for_answer))\n",
        "\n",
        "    self.images = [self.images[i] for i in range(len(self.images)) if i not in non_zero_rows]\n",
        "    #print(\"제거 후 남은 image 수\",len(self.images))\n",
        "\n",
        "    #문장 embedding\n",
        "  def __call__(self):\n",
        "    # 사전 훈련된 임베딩 행렬(self.word_embeddings)을 사용하여 Embedding 레이어 초기화\n",
        "    pretrained_embedding_matrix = self.word_embeddings_table\n",
        "    vocab_size = pretrained_embedding_matrix.shape[0]#행의 개수 = padding 토큰 포함 vocab 총 개수 (어휘사전 index = 행 index)\n",
        "    embedding_dim = pretrained_embedding_matrix.shape[1]#각 단어들의 embedding vector 크기\n",
        "    embedding_layer = Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[pretrained_embedding_matrix],\n",
        "        trainable=False)  # 임베딩 행렬을 고정\n",
        "#    print(\"embedded_sentences=\",embedded_sentences)\n",
        "    pretrained_embedding_matrix=tf.constant(pretrained_embedding_matrix,dtype=tf.float32)\n",
        "    #print(\"type of pretrained_embedding_matrix : \",type(pretrained_embedding_matrix))\n",
        "    return self.images, self.vocab, self.encoded_multi_labels, self.encoded_multi_labels_padded_for_answer , self.encoded_multi_labels_padded_for_answer.shape[1], self.idx2vocab, pretrained_embedding_matrix#self.encoded_multi_labels_padded는 모델의 정답\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l58A7XqViOKZ"
      },
      "outputs": [],
      "source": [
        "#모델 훈련 및 평가\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Dot, Dense, LSTM, Layer, Activation, Flatten\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences#문장 패딩해주는 애\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "class EncoderCNN(Model):#전이학습 한 번에 끝내기 위해 한 것\n",
        "  def __init__(self,embedding_dimension):\n",
        "    super().__init__()\n",
        "    #출력층 빠진(Flatten 전) vgg_model 객체 만들기\n",
        "    self.vgg=VGG16(weights=\"imagenet\",include_top=False)\n",
        "    #모든 layer는 trainable=True가 default이니, pretrained된 vgg는 그렇지 않게 설정하기 -> dense부분만 훈련될 수 잇게 하기\n",
        "\n",
        "    for layer in self.vgg.layers:\n",
        "      layer.trainable=False\n",
        "    self.flatten = Flatten()\n",
        "    self.dense1=Dense(units=512,activation=\"relu\")\n",
        "    self.dense2=Dense(units=256,activation=\"relu\")\n",
        "    self.dense3=Dense(units=embedding_dimension,activation=\"relu\")\n",
        "    self.bn = tf.keras.layers.BatchNormalization(momentum=0.01)\n",
        "    #print(\"dense1.trainable = \",self.dense1.trainable)\n",
        "    #print(\"dense2.trainable = \",self.dense2.trainable)\n",
        "    #print(\"dense3.trainable = \",self.dense3.trainable)\n",
        "\n",
        "  def __call__(self, image):\n",
        "     #1. 이미지 전처리\n",
        "    #print(\"Image type(변환 전) : \",type(image))\n",
        "    if not isinstance(image,tf.Tensor):\n",
        "      image = tf.constant(image,dtype=tf.float32)\n",
        "    if len(image.shape) != 4: \n",
        "      image = tf.expand_dims(image, axis=0)#개수(batch)에 대한 차원이 없으니, 차원 추가\n",
        "    # 이미지 크기 조절\n",
        "    if image.shape[1] != 224 or image.shape[2] != 224:\n",
        "      image = tf.image.resize_with_crop_or_pad(image, 224, 224)#(sample수, 224,224,3)or(224,224,3)으로 되돌려 줄 것\n",
        "    image = preprocess_input(image)#입력 이미지를 VGG16 모델 또는 다른 일부 모델에 맞게 사전 처리(평균 값 제거/채널 정규화)\n",
        "    x=self.vgg(image)\n",
        "    x=self.flatten(x)\n",
        "    x=self.dense1(x)\n",
        "    x=self.dense2(x)\n",
        "    x=self.dense3(x)\n",
        "    x=self.bn(x)\n",
        "    return x\n",
        "\n",
        "class DecoderRNN(Model):\n",
        "  def __init__(self, length_padded_sentence,embedding_dimension,hidden_size, vocab_size, embedding_table):\n",
        "    super().__init__()\n",
        "\n",
        "    self.length_padded_sentence = length_padded_sentence\n",
        "    self.hidden_size=hidden_size\n",
        "    self.embedding_table = embedding_table # embedding table은 word은 embedding vecctor로 바꾸는 matrix로, shape = (vocab_size,embedding_dimension)\n",
        "    self.vocab_size=vocab_size\n",
        "    self.lstm = LSTM(units=hidden_size, return_sequences=True, return_state=True) # units는 hidden state의 크기 의미\n",
        "    #input_shape입력 안 하면, 3차원 텐서가 input값임!(sample수, 문장 길이, emb_size)\n",
        "    self.prediction = Dense(units=vocab_size,activation=\"softmax\")\n",
        "\n",
        "  def __call__(self,images_features):# images_features shape = (sample 수,embedding_dimension)\n",
        "    #각 이미지 feature 벡터마다 한 문장(문장 길이 : length_padded_sentence)을 예측하는데\n",
        "    #방법은 하나의 image feature 벡터마다 단어 1개씩 예측하며 한 문장 만들기\n",
        "    Y=tf.zeros([0,self.length_padded_sentence,self.vocab_size],dtype=tf.float32)#예측값의 shape = (sample수, 문장길이, vocab_size)가 될 것이다.\n",
        "    for i in range(images_features.shape[0]):\n",
        "      predicted_words=tf.zeros([0,self.vocab_size])#shape = (문장길이,vocab_size)\n",
        "      feature = images_features[i]#차원 수가 (sample수,embedding_dimension) -> (sample수,)로 줄기에, 다시 크기 맞춰주기(for lstm input shape = (sample,문장길이,emb_size))\n",
        "      feature = tf.expand_dims(tf.expand_dims(feature,axis=0),axis=0)\n",
        "      embedded_word = feature\n",
        "      last_hidden_state = tf.zeros((1,self.hidden_size))#보통 state 초기값은 0으로 시작\n",
        "      last_cell_state = tf.zeros((1,self.hidden_size))\n",
        "      initial_state = [last_hidden_state,last_cell_state]\n",
        "      for j in range(self.length_padded_sentence):\n",
        "        hidden_states,last_hidden_state, last_cell_state=self.lstm(embedded_word,initial_state=initial_state)\n",
        "        #print(\"hidden_states = \\n\",hidden_states)\n",
        "        #print(\"last_hidden_state = \\n\",last_hidden_state)\n",
        "        #print(\"last_cell_state = \\n\",last_cell_state)\n",
        "        initial_state = [last_hidden_state,last_cell_state]#다음 word의 lstm에 intial state으로 들어갈 것.\n",
        "        next_word_probability = self.prediction(last_hidden_state)\n",
        "        predicted_words=tf.concat([predicted_words,next_word_probability],axis=0)\n",
        "        next_word_probability = tf.squeeze(next_word_probability)#벡터로 바꿔줌 -> shape = (vocab_size,)\n",
        "        next_word_idx = tf.argmax(next_word_probability)\n",
        "        embedded_word = self.embedding_table[next_word_idx]\n",
        "        embedded_word = tf.expand_dims(tf.expand_dims(embedded_word,axis=0),axis=0)\n",
        "        #이 for loop가 다 돌 때마다, 하나의 문장에 대한 확률 2차원 텐서 predicted_words가 완성된다.\n",
        "      predicted_words=tf.expand_dims(predicted_words,axis=0)\n",
        "      Y=tf.concat([Y,predicted_words],axis=0)\n",
        "    #print(\"Y shape = \", Y.shape)\n",
        "    return Y\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1JWFTpdjNUn"
      },
      "outputs": [],
      "source": [
        "class CNN_RNN(Model):\n",
        "  def __init__(self,sentences,images_numpy,embedding_dimension=16,hidden_size=64):#여기서 images_numpy는 행의 수 = 224, 열의 수 = 224로 전처리가 되어 있어야 한다!(for vgg)-2번째 셀\n",
        "    super().__init__()\n",
        "\n",
        "    self.word_processing_layer=word_processing_layer(sentences,images_numpy,embedding_dimension=embedding_dimension)\n",
        "    self.image_list, self.vocab, self.encoded_multi_labels, self.encoded_multi_labels_padded_for_answer , self.len_padded_sentence,self.idx2vocab,self.pretrained_embedding_matrix = self.word_processing_layer()\n",
        "\n",
        "    self.images = tf.zeros([0,224,224,3],dtype=tf.float32)\n",
        "    for image in self.image_list:\n",
        "      image = tf.image.resize_with_crop_or_pad(image, 224, 224)\n",
        "      image = tf.cast(image, tf.float32)\n",
        "      image = tf.expand_dims(image,axis=0)\n",
        "      self.images = tf.concat([self.images,image],axis=0)\n",
        "    #print(\"images shape = \",self.images.shape)\n",
        "\n",
        "    self.Encoder = EncoderCNN(embedding_dimension)#원래 분류할 땐, cnn에 클래스 수가 들어가지만, 여기선 이미지가 첫 단어를 뽑아내는 것으로 해석해서 emb size!\n",
        "    self.Decoder = DecoderRNN(length_padded_sentence=self.len_padded_sentence,embedding_dimension=embedding_dimension,hidden_size=hidden_size,vocab_size=len(self.idx2vocab),embedding_table=self.pretrained_embedding_matrix)\n",
        "\n",
        "  def __call__(self,images,training=False):\n",
        "    features=self.Encoder(images)#features = (sample 수, class 수)\n",
        "    #print(\"features shape : \",features.shape)\n",
        "    Y=self.Decoder(features)\n",
        "    #decoding layer에서 정수 인코딩 필요(beam search decoder에서만)\n",
        "    return Y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UsDYT1TJ1uLm",
        "outputId": "d5293be7-4bbd-4ca5-d498-6c3f860298df"
      },
      "outputs": [],
      "source": [
        "#main에 이어서 들어갈 부분\n",
        "cnn_rnn = CNN_RNN(multi_labels,image_list,embedding_dimension=16,hidden_size=64)\n",
        "#print(\"image 수 : \",len(cnn_rnn.images))\n",
        "#print(\"문장 수 : \",len(cnn_rnn.encoded_multi_labels_padded_for_answer))\n",
        "#print(\"문장 길이 : \",cnn_rnn.len_padded_sentence)\n",
        "#정답 라벨(self.encoded_multi_labels_paded)은 shape = (sample 수(batch_size),문장 길이)로, 이 때, shape[1]차원에 들어가는 애들은 단어들이 정수 인코딩 된 상태!(sparse_categorical_cross entropy일 때)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84Du8LSv1_ew",
        "outputId": "239a7cbe-4e1d-492c-cb20-c632ae857330"
      },
      "outputs": [],
      "source": [
        "#모델 훈련 및 평가(1,2중 하나)\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "callbacks_list=[EarlyStopping(monitor=\"val_accuracy\",patience=3),ModelCheckpoint(filepath=\"/content/checkpoint_path.keras\",monitor=\"val_loss\",save_best_only=True)]#callback 사용하기 위해 정의함.(model.fit에서)\n",
        "#1.데이터 split해서 훈련 데이터, train data로 나눠서 해보기( tf.data.Dataset.from_tensor_slices는 오류남)\n",
        "cnn_rnn.compile(optimizer='rmsprop',loss=\"SparseCategoricalCrossentropy\",metrics=[\"SparseCategoricalAccuracy\"])\n",
        "  # 데이터셋 생성\n",
        "dataset = tf.data.Dataset.from_tensor_slices((cnn_rnn.images, cnn_rnn.encoded_multi_labels_padded_for_answer))\n",
        "\n",
        "num_epochs=5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  #print(\"epoch = \",epoch+1)\n",
        "\n",
        "  # 데이터셋 섞기\n",
        "  dataset_p = dataset.shuffle(buffer_size=len(cnn_rnn.encoded_multi_labels_padded_for_answer))#에포크마다 dataset 다시 shuffle -> 새로운 훈련데이터셋, 테스트 데이터셋 만들기\n",
        "\n",
        "  # 훈련 세트와 테스트 세트로 나누기 + 평가\n",
        "  train_size = int(0.8 * len(cnn_rnn.encoded_multi_labels_padded_for_answer))  # 전체 데이터 중 80%를 훈련 세트로\n",
        "  test_size = len(cnn_rnn.encoded_multi_labels_padded_for_answer) - train_size  # 나머지 20%를 테스트 세트로\n",
        "  train_dataset = dataset_p.take(train_size)\n",
        "  test_dataset = dataset_p.skip(train_size)\n",
        "  cnn_rnn.fit(train_dataset,batch_size=64,callbacks=callbacks_list)\n",
        "  test_loss, test_accuracy = cnn_rnn.evaluate(test_dataset,batch_size=64)\n",
        "  #print(f'Test loss: {test_loss}, Test accuracy: {test_accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pY7oCYXwh3p"
      },
      "outputs": [],
      "source": [
        "#모델 실 사용\n",
        "import tensorflow as tf\n",
        "class Node():#이렇게 내부 클래스 가능\n",
        "  def __init__(self,word_index,probability,prev_node,next_nodes,num_layer,model):\n",
        "     self.word_index=word_index\n",
        "     if prev_node != None and prev_node !=[]:#prev_node !=[]는 tail의 prev_node만 list로 여러 개 오기 때문에, 처음 tail 생성시 필요\n",
        "       #print(\"head or tail 아님\")\n",
        "       if model.idx2vocab[word_index] != \"end\" and model.idx2vocab[word_index] != \"<pad>\" and num_layer>=2:\n",
        "        #print(\"end or pad 아님\")\n",
        "         #self.probability=prev_node.probability-tf.math.log(probability*self.length_penalty(num_layer))\n",
        "        self.probability=prev_node.probability-tf.math.log(probability/0.8)#length penalty로 둘 중 하나 선택하기\n",
        "       else:\n",
        "        #print(\"end or pad임\")\n",
        "        self.probability=prev_node.probability-tf.math.log(probability)#end 토큰이 나올 때까지 beam search에서 이 과정이 반복될 텐데, 그럼, end토큰이 있는 노드들의 probability중 가장 작은 값을 가진 토큰의 path가 가장 맞을 확률이 높은 path가 된다!\n",
        "     else :\n",
        "      #print(\"head or tail임\")\n",
        "      self.probability=-tf.math.log(probability)#head, tail 때문에 이렇게 했음.\n",
        "      #print(\"head의 probability : {}, -tf.math.log(probability) : {},누적확률 : {}\".format(probability,-tf.math.log(probability),self.probability))\n",
        "\n",
        "     self.prev_node = prev_node\n",
        "     self.next_nodes = next_nodes#이 노드 객체의 word로부터 딥러닝 모델을 거처 예상된 k개의 후보 단어들을 저장할 각각의 노드들로, list에 노드들이 각각 들어갈 것임\n",
        "     self.num_layer = num_layer#이 노드가 몇 번째 layer에 있는지 의미(int임)\n",
        "     if word_index != None:\n",
        "      print(\"{}번째 층의 node의 word : {}, probability : {}, -tf.math.log(probability) : {},누적확률 : {}\".format(num_layer,model.idx2vocab[word_index],probability,-tf.math.log(probability),self.probability))\n",
        "\n",
        "class BeamSearchDecoder():#약간만 수정하면 다른 모델에도 응용할 수 있게 만들었음\n",
        "  def __init__(self, beam_size, model):#여기서 모델은 train이 끝난 모델로, CNN_RNN 모델 객체가 들어갈 것!\n",
        "    self.beam_size=beam_size\n",
        "    self.idx2vocab=model.idx2vocab#인덱스에 단어 대응시키는 어휘사전 필요\n",
        "    self.Encoder = model.Encoder#image를 넣어 start 단어 만들 것\n",
        "  # print(\"self.CNN까진 오류 없음\")\n",
        "    self.lstm = model.Decoder.lstm\n",
        "    self.prediction_layer = model.Decoder.prediction\n",
        "    self.pretrained_embedding_matrix=model.pretrained_embedding_matrix\n",
        "    self.len_padded_sentence = model.len_padded_sentence\n",
        "    self.model = model\n",
        "    self.num = 0#문장 길이만큼 prediction 반복시 그만하게 하게 할 것\n",
        "  #  print(\"self.num까진 오류 없음\")\n",
        "    self.head = Node(None,1.0,None, None,0,model) ; self.tail = Node(None,1.0,list([]),None,self.len_padded_sentence,model)\n",
        "  #  print(\"head, tail 정의까진 ...\")\n",
        "    self.head.next_nodes = self.tail#head의 word index에는 CNN을 거쳐 예측한 첫 단어의 index가 들어가고, 이에 맞는 probability가 들어갈 것\n",
        "  def __call__(self, Image):#전처리 안 된 것이어도 상관 없음. CNN에서 하게 했음.\n",
        "    #head 노드에 정보 완벽히 넣기(즉, start word 뽑기 ) -> 이후, 이로부터 beam_search 시작\n",
        "    start_word_feature = self.Encoder(Image)#shape = (sample수, emb_size)인데, lstm의 input형태 맞추기 위해 axis=1에 차언 추가하기\n",
        "    start_word_feature = tf.expand_dims(start_word_feature,axis=1)\n",
        "    hidden_states, last_hidden_state, last_cell_state = self.lstm(start_word_feature) \n",
        "    #print(\"cnn 결과값 = \\n\",start_word_feature)\n",
        "    #print(\"cnn 결과값 shape = \",start_word_feature.shape)\n",
        "\n",
        "    initial_state = [last_hidden_state,last_cell_state]\n",
        "    Y = self.prediction_layer(hidden_states) # (sample수, 문장 내 단어 수, vocab_size) | 어차피 단어 1개만 넣었기에, shape만 1차원 차이나지, hidden_states= last_hidden_state\n",
        "\n",
        "    #첫 단어(start_word_feature)로부터 beam_size 개의 예측 단어 뽑아서 for 문으로 여기서부터 prediction 시작\n",
        "      #첫 단어로부터 예측되는 단어들의 확률(Y)의 index을 beam_size개 봅기(큰 거부터 차례대로)\n",
        "    #print(\"sort 전 Y shape = \",Y.shape)\n",
        "    sorted_indices = tf.argsort(Y,axis=2,direction='DESCENDING')\n",
        "    top_k_indices = sorted_indices[:,:,:self.beam_size]\n",
        "    max_indexes = tf.squeeze(top_k_indices)\n",
        "    max_indexes = max_indexes.numpy().tolist()\n",
        "      #이 index로부터 각각의 확률 뽑기 -> 이들이 최대 확률\n",
        "    probabilities = list([])\n",
        "    Y=tf.squeeze(Y)\n",
        "    for i in range(self.beam_size):\n",
        "      probabilities.append(Y[max_indexes[i]])\n",
        "    #print(\"첫번째 예측 확률(node에 저장 전(즉, -log 씌우기 전)) : \",probabilities)\n",
        "      #첫 단어로부터 예측 단어 beam_)size개 봅기\n",
        "    next_words = self.insert(max_indexes,probabilities=probabilities,present_node = self.head)#insert 함수를 보면 알 수 있듯이, next_words는 노드 객체 리스트임!\n",
        "\n",
        "    #beam_search시작\n",
        "    for word in next_words:\n",
        "      self.prediction(word,initial_state, start_word_feature,self.beam_size)#beam_search 시작 -> tail의 previous node(end 토큰)\n",
        "    #path찾기\n",
        "    sentence = self.search_max_prob_nodes(self.tail)\n",
        "\n",
        "    return sentence\n",
        "\n",
        "  def insert(self, word_indexes, probabilities, present_node):\n",
        "    present_node.next_nodes = list([])#원래 가장 최근 노드는 tail을 가리키고 있지만, 이를 list로 만들고\n",
        "    for i in range(self.beam_size):#word_indexes, probabilities 모두 beam_size일 테니,\n",
        "      present_node.next_nodes.append(Node(word_indexes[i],probabilities[i],present_node,self.tail,present_node.num_layer+1,self.model))#present_node, self.tail을 가리키는 노드 만들기\n",
        "    for i in range(self.beam_size):#그리고 이렇게 생성된 새로운 노드들(present_node.next_nodes) 중, end 토큰을 저장한 애들은\n",
        "      if self.idx2vocab[word_indexes[i]] == \"end\":\n",
        "        self.tail.prev_node.append(present_node.next_nodes[i])#tail이 직접 이들을 가리키게 해, 이후, path들 중, 확률 제일 높은 것을 뽑을 것\n",
        "#        print(\"present_node.next_nodes[i].probability = \", present_node.next_nodes[i].probability)\n",
        "    return present_node.next_nodes\n",
        "\n",
        "  def prediction(self,word, initial_state, img_feature, beam_size):\n",
        "    #여기서 img_feature shape = (sample수=1, embedding_size)이어야 함!\n",
        "    embedded_word = self.pretrained_embedding_matrix[word.word_index,:]\n",
        "#    print(\"embedded_word.shape = \",embedded_word.shape)#lstm의 input으로 들어가야 되니 (batch size=1,문장길이 = 1, embedded size)여야 한다!\n",
        "    if len(embedded_word.shape) == 1:#차원 2개 더 필요(batch, 문장길이)\n",
        "      for i in range(2):\n",
        "        embedded_word = tf.expand_dims(embedded_word,axis=0)\n",
        "    elif len(embedded_word.shape) == 2:\n",
        "      embedded_word = tf.expand_dims(embedded_word,axis=0)\n",
        "#    print(\"교정 후 embedded_word.shape = \",embedded_word.shape)\n",
        "    hidden_states, last_hidden_state, last_cell_state  = self.lstm(embedded_word,initial_state=initial_state)\n",
        "\n",
        "    initial_state = [last_hidden_state,last_cell_state]#다음 word의 lstm에 intial state으로 들어갈 것.\n",
        "    #여기 shape 확인해서 고치기\n",
        "    Y = self.prediction_layer(hidden_states)\n",
        "    sorted_indices = tf.argsort(Y, axis=2, direction='DESCENDING')\n",
        "    top_k_indices = sorted_indices[:, :, :beam_size]\n",
        "    max_indexes = tf.squeeze(top_k_indices)#크기가 1인 차원은 모두 없어질 것\n",
        "    max_indexes = max_indexes.numpy().tolist()#1차원 리스트로 바꾸기\n",
        "#    print(\"max_indexes = \",max_indexes)\n",
        "    probabilities = list([])\n",
        "    Y=tf.squeeze(Y)#vocab_size만 남을 것! -> shape = (vocab_size,)\n",
        "    for i in range(beam_size):\n",
        "      probabilities.append(Y[max_indexes[i]])#가장 큰 확률부터 내림차순으로 probabilities list에 들어가기에, max_indexes와 각 원소가 순서대로 대응된다.\n",
        " #중요(실제 사용시엔, num_layer>=self.tail.num_layer여야 함)\n",
        "    next_words = self.insert(max_indexes,probabilities = probabilities,present_node=word)#word의 next_node들 만들어냄. | next_words는 node 객체 list임!\n",
        "\n",
        "    for i in range(len(next_words)):#이를 보면 알 수 있는 특정 노드(word)에서 beam_size만큼의 노드 후보를 예측하고, \"end\" word 또는 \"<pad>\"토큰이 나오는 것까지 반복하는 것을 재귀함수로 나타낸 것!\n",
        "      if self.idx2vocab[next_words[i].word_index] == \"end\" or self.idx2vocab[next_words[i].word_index] == \"<pad>\" or next_words[i].num_layer>=self.tail.num_layer:\n",
        "        continue\n",
        "      self.prediction(next_words[i], initial_state, img_feature, beam_size)\n",
        "\n",
        "  def search_max_prob_nodes(self,Node):#__call__에서 이 함수를 쓸 건데, Node=tail이 될 것\n",
        "    #Node의 previous 노드 중 가장 큰 확률 가진 노드 찾기 -> 확률에 -log가 씌워져있기에, probability 제일 작은 노드 찾기\n",
        "    prob_list=list([])\n",
        "    for prev_node in Node.prev_node:\n",
        "      prob_list.append(prev_node.probability)\n",
        "    min_value = min(prob_list)\n",
        "\n",
        "    # 가장 작은 수의 인덱스 찾기\n",
        "    min_index = None\n",
        "    for index, value in enumerate(prob_list):\n",
        "      if value == min_value:\n",
        "        min_index = index\n",
        "        break\n",
        "\n",
        "    answer_end_node = Node.prev_node[min_index]#이 answer_end_node가 end토큰 노드임.\n",
        "    #이 min_index의 end 토큰 노드부터 head노드까지 올라가며 문장(list) 만들기\n",
        "    sentence = list([])\n",
        "    Node = answer_end_node.prev_node#end토큰은 문장에 쓸 필요없으니, 이 다음 노드의 단어부터 들어갈 것\n",
        "\n",
        "    while Node.num_layer != 0:\n",
        "\n",
        "      #print(\"현재 num_layer = \",Node.num_layer)\n",
        "      #print(\"예측 단어 : \",self.idx2vocab[Node.word_index])\n",
        "      sentence.append(self.idx2vocab[Node.word_index])\n",
        "      #print(\"word probability = \",tf.math.exp(-Node.probability))\n",
        "      Node = Node.prev_node\n",
        "    sentence.reverse()\n",
        "    #print(sentence)\n",
        "    return sentence\n",
        "  def print_nodes(self,Node):#노드들 제대로 작동하는지 확인용\n",
        "    while True:\n",
        "      if Node == self.head:\n",
        "        print(self.idx2vocab[Node.word_index])\n",
        "      if Node.num_layer < 9:\n",
        "        for i in range(len(Node.next_nodes)):\n",
        "          print(self.idx2vocab[Node.next_nodes[i].word_index],end=\" \")\n",
        "          self.print_nodes(Node.next_nodes[i])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T84m44KanbnV",
        "outputId": "d65c7f12-038e-45cb-a2af-09f38b62ca5d"
      },
      "outputs": [],
      "source": [
        "beamsearch=BeamSearchDecoder(beam_size=2,model = cnn_rnn)\n",
        "sentence = beamsearch(image_label.rare_images[100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "jcGv0ImWlX7D",
        "outputId": "c8cdf517-8307-4d29-83c5-b25429e81e84"
      },
      "outputs": [],
      "source": [
        "#위의 셀에서의 beam search answer와 비교해볼 것\n",
        "from PIL import Image\n",
        "from IPython.display import display  # Jupyter Notebook에서 이미지를 출력하기 위해 사용\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# 이미지 출력\n",
        "def check_answer(index):\n",
        "  display(image_label.rare_images[index])\n",
        "  print(multi_labels[index])\n",
        "check_answer(100)\n",
        "#print(type(image_label.rare_images[1499]))\n",
        "#image = tf.constant(image_label.rare_images[1499])\n",
        "#print(image.shape)\n",
        "#print(image)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
